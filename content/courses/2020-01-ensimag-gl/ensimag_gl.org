# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Du /Machine Learning/ en Production
#+AUTHOR: Kévin CAYE
#+LANGUAGE: fr

# reveal options: see https://github.com/yjwen/org-reveal
#+REVEAL_ROOT: ../js/reveal.js/
#+REVEAL_TRANS: none
#+REVEAL_PLUGINS: (highlight notes)
#+OPTIONS: reveal_center:nil reveal_progress:t reveal_history:nil reveal_control:t
#+OPTIONS: reveal_rolling_links:t reveal_keyboard:t reveal_overview:t num:nil toc:nil
#+OPTIONS: reveal_width:1200 reveal_height:800
#+REVEAL_THEME: white
#+REVEAL_HLEVEL: 1 ## all header on same lvl
#+REVEAL_SPEED: fast
#+REVEAL_EXTRA_CSS: ./extra.css
#+REVEAL_EXTRA_JS:


#+BEGIN_SRC emacs-lisp :eval no-export :exports none
(execute-kbd-macro "\C-c\C-evv")
#+END_SRC

#+RESULTS:

* Qui je suis ?
- Ancien Ensimag (promotion 2014)
- Thèse en méthodes statistiques appliquées à la génétique
- /Data scientist/ depuis deux ans

#+BEGIN_NOTES
- Donc pour moi le génie logiciel c'est un outils ! j'ai vaguement abbordé
  ca à l'ensimag ....
- Mais c'est indispensable dans mon travail
#+END_NOTES
* Plan et objectifs

*Objectifs*

Répondre à la question:
- Comment déployer une solution logiciel utilisant un modèle d'intelligence
  artificiel en production ❓

#+BEGIN_NOTES
Pour ca on va essayer de balayer les différentes spécificité des projets machine
learning.
#+END_NOTES

* Du développement à la production
** /Machine learning/
*Une définition pour un informaticien*

#+begin_quote
Machine Learning is the science (and art) of programming computers so they can
learn from data.
#+end_quote

#+ATTR_REVEAL: :frag (appear)
*Quant utiliser le /machine learning/*
#+ATTR_REVEAL: :frag (appear)
- les problèmes résolus en énumérant un grand nombre de règles
- les problèmes très complexes ou trouver toutes les règles serait impossible
- les problèmes ou les règles peuvent changer, ou il faut s'adapter à de
  nouvelles données

*** Exemple: approche traditionnelle d'un filtre anti-spam
#+HTML: <img src="./figures/traditional_workflow.png" align="middle">
*** Exemple: approche /Machine Learning/ d'un filtre anti-spam
#+HTML: <img src="./figures/ml_workflow.png" align="middle">
** Le /Machine Learning/ prend très peu de place dans un projet

#+HTML: <img src="./figures/ml_system.jpg" align="middle">

#+ATTR_REVEAL: :frag (appear)

En quoi le /Machine Learning/ complique le développement logiciel ?

#+BEGIN_NOTES
- ml représente une petite partie du système complet !
- le premier déploiement peut être simple
- par contre si on pense pas le système complet la dette technique arrive avec
  - la maintenance
  - la mise a jours des modèles
  - le monitoring des modèles

On va essayer dans la suite de balayer ces différents aspects

ref: [[https://christophergs.github.io/machine%2520learning/2019/03/17/how-to-deploy-machine-learning-models/][1. Why are ML Systems Hard?]]
#+END_NOTES
** Les trois axes de changement dans un projets /Machine Learning/

#+HTML: <img src="./figures/ml-axis-of-change.png" align="middle">

#+BEGIN_NOTES
En plus du code les données utilisé pour entraîner le modèle ainsi que les choix
de modèle peuvent changer. Nos systèmes doivent être capable de stocker et
versionner les données et les modèles.

ref: [[https://martinfowler.com/articles/cd4ml.html?utm_campaign=Data_Elixir&utm_medium=email&utm_source=Data_Elixir_250#ml-axis-of-change.png][the 3 axis of change in a Machine Learning application]]
#+END_NOTES

** La production
#+HTML: <img src="./figures/mem_prod.png" align="middle">

#+BEGIN_NOTES
Pour comprendre la suite il faut d'abord définir la production

Faire un petit script avec du ml tout le monde peut le faire.

Mettre en production c'est rendre notre système disponible accessible aux client !

#+END_NOTES
** Un exemple simple de mise en production d'un modèle

#+HTML: <img src="./figures/team0.png" align="middle">

#+BEGIN_NOTES
C'est l'exemple le plus simple ou on entraîne un fois le modèle et on le
déploie.
#+END_NOTES
** Qu'est ce qu'on déploie ?
#+ATTR_REVEAL: :frag (appear)
1. *Le modèle entraîné sérialisé*
  #+BEGIN_SRC python
  model = load("model.pkl")
  #+END_SRC
2. *Le code pour faire la prédiction:*
  #+BEGIN_SRC python
  def predict(data):
      return model.predict(data)
  #+END_SRC

** Comment on le déploie ?
#+HTML: <img src="./figures/monolithic_vs_microservice.png" align="middle">

#+BEGIN_NOTES
D'un coté on a un architecture micro service contre monolitique.

On a coutume de faire des micro service car les enviromment qui font du machine
leaning font appel à des stack logiciel très particulière (numpy + tensorflow
par exemple) qui peut être très différents du reste du système il est donc
préférable de l'isoler pour bien la controler.
#+END_NOTES
** Déploiement du modèle comme un /Web Service/
#+HTML: <img src="./figures/components.png" align="middle">


#+BEGIN_NOTES
Le client accède au function du modèle grace à une api !

Cette interface ne dois pas changer pour assurer la compatibilité avec le
client.

Ok donc on arrive déployé des modèle simple mais pourquoi c'st si dure le MLM en
production?
#+END_NOTES

** Les modèles                                                  :noexport:

#+begin_quote
*Dans un système complexes les modèles*
1. sont influencés par les nouvelles données
2. sont compliqués a couplés et étendre
3. ont des interaction complexe entre eux
#+end_quote

#+BEGIN_NOTES
Par exemple:
1. exemple de google traduction
2. un modèle qui reconnaît des image et un modèle devine la suite de la phrase ne
   donne pas un modèle qui écrit des légende d'image
3. exemple d'un modèle de prédiction de la météo et de prédiction de la
   consonassions d'un bâtiment. L'erreur du model1 doit être connu et elle est
   importante lors de l'apprentissage !

Donc on a un problème avec un des principe de base en génie logiciel: le
découplage.
#+END_NOTES
** L'équipe

#+HTML: <img src="./figures/team_silo.png" align="middle">

#+begin_notes
Déjà pour ce cas simple il faut beaucoup de compétences
#+end_notes
** L'équipe
#+HTML: <img src="./figures/dev_ops.png" width="100%">


#+begin_notes
Historiquement les data scientist sont très loin de des gens qui organise le
déploiement de la solution logiciel.

On avait une organisation en silo.

#+end_notes
** La culture /DevOps/

#+HTML: <img src="./figures/devops_cycle.png" align="middle">

#+begin_notes
Afin de réunir toutes ses compétences il y a une facon d'organisé les équipe
basé sur la culture devops.

DevOps vient de la contraction de dev (ceux qui développe la solution) - ops
(ceux qui gère les infrastructure de production). L'idée est de faire tout dans
la mème équipe.

On brise les silo et L'équipe est organisé autour d'un but précis! déployer un
web service avec du machine learning dedans !

#+end_notes

** Une équipe pluridisciplinaire

#+HTML: <img src="./figures/devops.png" width="100%">

** La mise à jour du modèle
#+HTML: <img src="./figures/ml-pipeline-1.png" align="middle">

#+begin_notes
On a résussi a deployer un modèle une fois. Mais que ce passe t il si on veut
mettre à jour le modèle ? Il faut s'organiser pour ca !

Il faut une très grande rigueur dans la reproduction du l'entrainement.

On peut vouloir comparer les modèles entre eux.
#+end_notes
** Mettre à jour un modèle en production

#+HTML: <img src="./figures/canary-release-2.png" align="middle">

#+begin_notes
Notre nouveau modèle est près comment on met à jour la production ?

C'est pas une problématique propre au machine learning.

Une stratégie possible est de ne déployé que pour 5% des utilisateurs
#+end_notes
** Tester un nouveau modèle avant de le déployer                  :noexport:
*** A/B test
** La dépendance au données coûte plus chère que la dépendance au code

#+REVEAL_HTML: <div class="column" style="float:left; width: 50%">

#+HTML: <img src="./figures/xkcd_data.png" align="middle">

#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class="column" style="float:right; width: 50%">

#+ATTR_REVEAL: :frag (appear)
1. Les données peuvent être instable
2. Il est difficile de détecter des données peu utilisées
3. Chaque nouvelle donnée ouvre une vulnérabilité

#+REVEAL_HTML: </div>

#+BEGIN_NOTES
Enfin une des particularité est système employant le machine learning est la
dépendance aux données.

1. Comme par exemple si un modèle prend en entré des prédiction d'un autre
   modèle. Si cette autre modèle est mis a jours on peut avoir a changer notre
   modèle.

   Les données peuvent aussi venir d'un autre composent géré par une autre
   équipe.

   Une solution est de fixé et versionner les données utilisé, il
   faut dont pouvoir gerer ca.
2. Detecter une dépendance à un package peut utilisé est facile. Par contre pour
   des données peut utilisé c'est plus dure. Le problème c'est que chaque
   dépendence à des données peu utile laisse une vulnérabilité inutile.
3. que ce soit au moment de l'entrainement ou de la prédiction. C'est une entré
   pour nos utilisateurs. Cette entré peut faire tomber notre système.

Il faut donc etre très précocionneur quand on traite des données.

cite:sculley2015hidden
#+END_NOTES

** Un processus de deploiment continue pour le /Machine Learning/

#+HTML: <img src="./figures/cd4ml-end-to-end.png" align="middle">

#+BEGIN_NOTES
Si on résume ce qui à été dit on peut voir le déploiement d'une solution reposant
sur le /machine learning/ comme la succession de ces étapes.

On voit ici les différentes étapes du processus de déploiement ainsi que les
artefact qui correspondent à chaque étape.

1. on entrain des modèle sur des données static (train

2. on a des modèle candidat qu'on peut comparé sur des donénes de test (jamais vu pendant l'entrainement

3. un modèle est choisie et on peut le testé en tant que modèle en production
   c'est dans sont enviromment de prod fournissant des prédiction à travers une api
4. puis on déploie et on monitor le comportement du modèle en production. Ces
   bug, si c'est de la prédiction on voir si il a juste ou pas ?
5. et On recommence


d'après [[https://martinfowler.com/articles/cd4ml.html?utm_campaign=Data_Elixir&utm_medium=email&utm_source=Data_Elixir_250][Continuous Delivery for Machine Learning]]
#+END_NOTES

** Les points clés de la production                               :noexport:
:LOGBOOK:
- Note taken on [2019-12-17 mar. 12:56] \\
  définir les concepts du tableau après
:END:

*** Entraînement du modèle
- offline par un data scientiste
- Tous les jours à heure fixe
- Sur un flux de données
*** Prédiction du modèle
- Tous les jours à heure fixe
- A la demande d'un utilisateur
- Sur un flux de données
*** Gestion du système
- Mesure les performances du modèle
  - prédiction (precision du modèle)
  - métier (indicateur metier)
- Mesure de la qualité des données entrantes, est ce que les données entrantes dérivent ?
*** Mise à jour du système
- Comment déployer un nouveau modèle ?
- Quand déployer un nouveau modèle ?
** Quelques architectures d'une application /Machine Learning/    :noexport:

|--------------+------------+--------------+----------------------|
| /            | <          |              | >                    |
|              | BD partagé | Rest Api     | Streaming            |
|--------------+------------+--------------+----------------------|
| Entraînement | Batch      | Batch        | Streaming            |
|--------------+------------+--------------+----------------------|
| Prédiction   | Batch      | A la demande | Streaming            |
|--------------+------------+--------------+----------------------|
| Exemple      | météo      | pub en ligne | Detection de fraudes |
|--------------+------------+--------------+----------------------|

#+BEGIN_NOTES
- Rest api
- Streaming:
  - necessite des techno qui gère des flux de données come Kafka
  - a chaque fraude/faute detecté quand on a le feedback on peut réentréner le
    modèle pour s'adaptéer à la situation
#+END_NOTES
*** Un exemple d'architecture
#+HTML: <img src="./figures/example_architecture.jpg" align="middle">
** Une pipeline de travail pour un projet Machine Learning        :noexport:
#+HTML: <img src="./figures/ml_gl_workflow.png" align="middle" width="140%">

#+BEGIN_NOTES
Maintenant qu'on a dit tous ca comment on travail sur un projet data science. On
peut essayer de se donner un workflow.

Mais c'est pas suffisent.

Faire du machine learning c'est bien mais si ca ne va jamais en production ca ne
sert a rien ! Il faut donc bien comprendre ce qu'est la production.

cite:amershi2019software
#+END_NOTES

* Quelques anti-patrons

#+HTML: <img src="./figures/tech_debt.jpg" align="middle">

#+BEGIN_NOTES
les anti-patrons ou antipatterns sont des erreurs courantes de conception des
logiciels.

C'est eux qui creer ce qu'on appel de la dête technique. C'est le temps qu'on va
devoir supplémentaire passer dans le futur pour continuer à faire vivre notre
système mal conçu !

#+END_NOTES
** TODO Boucle d'interaction

** /Glue Code/

#+ATTR_REVEAL: :frag (appear)
1. *Desciption*
   - On utilise des solutions génériques pour faire en /machine learning/
     (exemple: /sklearn/, /keras/)
   - On code pour faire marcher différentes briques ensembles
2. *Problèmes*
   - Système est gélé, on ne veux pas tester d'autres alternatives
   - On a du mal à intégrer la logique metier dans le code
3. *Une solution*
   - Développer la solution complète peut être moins coûteux
   - Développer des interface au dessus de paquets /black box/

#+BEGIN_NOTES
Un premier anti patron est ce qui est appelé le glue code en anglais. C'est le
code ciment

1. Vous avez du l'experimenter on code surtout entre les appel au bibliotheque
   de ML
2. Par exemple on peut avoir du mal a modifier la fonction objectif pour
   integrer la logique metier.
3. Ca permet d'avoir un système plus robuste au changement

#+END_NOTES

** /Pipeline Jungles/
#+ATTR_REVEAL: :frag (appear)
1. *Desciption*
   - les données doivent être arrangé pour être compatible avec les api des modèles
   - on creer beaucoup de nouvelle caractéristique
2. *Problèmes*
   - quand des nouvelles données arrive ont ne factorise pas forcement tous
   - plus la /pipeline data/ est complexe plus elle sera dure a maintenir et debugger
3. *Une solution*
   - Il faut repenser la /pipeline/ des données depuis le début
** Code expérimental mort
#+ATTR_REVEAL: :frag (appear)
1. *Desciption*
   - Une conséquence des anti-patrons /Pipeline jungles/ et /glue code/, il peut
     être intéressant d'utiliser des branchements conditionnels pour faire des
     expériences.
2. *Problèmes*
   - Les branchements conditionnel rende les compatibilités complexe
3. *Une solution*
   - Il faut éviter ce genre de branchement
   - examiner le code périodiquement et supprimer ceux qui sont mort
#+BEGIN_NOTES
#+END_NOTES

** Manque d'abstraction
1. *Desciption*
   - Pas d'abstraction commune pour décrire les système reposant sur le /Machine learning/
2. *Problèmes*
   - Les abstractions sont à la base du génie logiciel

   #+BEGIN_NOTES
   1. manque des fameux design pattern
   2. c'est ce qu'on fait en gl et qui nous permet de construire des système robuste au changement
   #+END_NOTES

** Un exemple de patron: /Map-reduce/

#+HTML: <img src="./figures/mapreduce-fonctionnement.png" align="middle">

#+BEGIN_NOTES
C'est un patron très utilisé pour le calcule parallèle sur plusieurs machine

Pour ce patron on a deux fonction
- =map= qui permet de distribuer le travail sur différent noeud
- =reduce= qui permet calculer le resultat sur chaque cluster

Ce design pattern fucntion très bien pour beaucoup de traitement de données.
Mais pas pour l'apprentissage

#+END_NOTES


* Un exemple                                                       :noexport:

#+BEGIN_NOTES
Ce n'est pas du tout une méthode systématique pour consevoir, c'est juste
l'étude d'un cas concret (Schneider Electric).

Je vous exposer le problème technique, les contraintes et comment ils ont
répondu au problème.
#+END_NOTES

** La problématique
#+REVEAL_HTML: <div class="column" style="float:left; width: 50%">

#+HTML: <img src="./figures/smart_building.jpg" align="middle">

#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class="column" style="float:right; width: 50%">

#+ATTR_REVEAL: :frag (appear)
- 40% de l'energy modial est dépensé dans les batiments
- optimization de la consomation energétique (energie renouvlable, batterie)
- la première étape est de pouvoir *prédire la consomation d'un batiment*
#+REVEAL_HTML: </div>

#+BEGIN_NOTES
On pose le decors. On S'attend a ce que les batiment de demain embarque du
machine learning !

Etre capable de prédire la consommation est la première étape.
#+END_NOTES

** Le contexte                                                    :noexport:

#+ATTR_REVEAL: :frag (appear)
1. Équipe de R&D qui historiquement fait propose des prototype qui démondre une
   faisabilité.
2. Les clients ?
   - d'autres equipes de l'entreprise
   - des exterieurs à l'entreprise

#+BEGIN_NOTES
1. donc l'équipe n'est pas habitué à dévelloper des logiciels, à mettre en
   production
2. Questions très importante ! pourquoi on fait ca ?
   - pour intégrer notre system dans une solution plus grande, on connait un peu
     leur solution, on peut envisager un acompgnement
   - pour en faire ce qu'ils veulent ! on rentre en concurence avec plein de
     personne. En gros si on veux que ca se vendent ca à interet à etre bon !
#+END_NOTES

** Comment valider ?
** Comment déployer ?
** Comment surveiller ?
** Comment faire évoluer ?
** Comment faire de l'intégration/déploiement continue ?
* Références
- cite:geron2017hands
- cite:amershi2019software
- cite:sculley2015hidden
- [[https://blog.acolyer.org/2019/07/08/software-engineering-for-machine-learning/][Morning paper: Software engineering for machine learning: a case study]]
- [[https://martinfowler.com/articles/cd4ml.html?utm_campaign=Data_Elixir&utm_medium=email&utm_source=Data_Elixir_250][Continuous Delivery for Machine Learning]]
- [[https://fr.slideshare.net/turi-inc/machine-learning-in-production][Machine learning in production]]
- [[https://docs.oracle.com/fr/solutions/learn-architect-microservice/index.html#GUID-1A9ECC2B-F7E6-430F-8EDA-911712467953][Différences entre les microservices et l'architecture unilithic]]

#+REVEAL: split
bibliography:~/bibliotheque/bibliotheque.bib
