# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: De l'Intéligence Artificielle en Production
#+AUTHOR: Kévin CAYE
#+LANGUAGE: fr

# reveal options: see https://github.com/yjwen/org-reveal
# #+REVEAL_ROOT: ../js/reveal.js/
#+REVEAL_TRANS: none
#+REVEAL_PLUGINS: (highlight notes)
#+OPTIONS: reveal_center:nil reveal_progress:t reveal_history:t reveal_control:t
#+OPTIONS: reveal_rolling_links:t reveal_keyboard:t reveal_overview:t num:nil toc:nil
#+OPTIONS: reveal_width:1200 reveal_height:800
#+REVEAL_THEME: white
#+REVEAL_HLEVEL: 1 ## all header on same lvl
#+REVEAL_SPEED: fast
#+REVEAL_EXTRA_CSS: ./extra.css
#+REVEAL_EXTRA_JS:


#+BEGIN_SRC emacs-lisp :eval no-export :exports none
(execute-kbd-macro "\C-c\C-evv")
#+END_SRC

#+RESULTS:

* Qui je suis ?
- Ancien Ensimag (promotion 2014)
- Thèse en méthodes statistiques appliquées à la génétique
- Ingénieur de recherche en intelligence artificiel (IA) depuis trois ans
- je travaille actuellement pour [[https://www.probayes.com/][Probayes]]

* Objectifs et plan du cours
*Répondre à la question :*
- Comment developper une solutiond'intelligence artificielle ❓

*Plan*
- Méthode de travaille pour le dévellopement d'un modèle d'apprentissage automatique
- Déploiement d'un modèle d'apprentissage automatique

* Développement d'un modèle d'apprentissage automatique
** Qu'est ce que l'apprentissage automatique ?
*** Exemple: approche traditionnelle
[[./figures/traditional_workflow.png]]
*** Exemple: approche /Machine Learning/
[[./figures/ml_workflow.png]]
#+BEGIN_NOTES
- Quand on parle de le modèle de machine learning, c'est en faite l'ensemble des
  règles aprise automatiquement. A partir des données.
#+END_NOTES
** Quelques exemples
*Vision par ordinateur*
- Extraction de l'adresse d'une enveloppe postale à partir d'images
*Traitement automatique des langues*
- Détection des mails indésirables
- Traduction
*Séries temporelles*
- Prédiction de la consomation energetique d'un batiment
*Données tabulaires*
- Système de recommandation

#+BEGIN_NOTES
- Le machine learning addresse plein de dommaine comme par exemple
- Données tabulaire car pour chaque individu on a un ensemble de caractéristique
  (ou features dans le garguon) et on veux prédire par exemple une vidéo qui
  optimise les chance de click.
#+END_NOTES

** Quelques mots sur le travail d'ingénieur de recherche en /data science/
:PROPERTIES:
:ID:       ec3b1867-507c-4633-8795-95b051ac0b90
:END:
- Un client vient avec des *données* et une problématique
- On doit proposer du *code* qui va entrainer un *modèle* qui résoud sa
  problématique

#+ATTR_REVEAL: :frag (appear)
[[attachment:_20210126_102404screenshot.png]]

#+BEGIN_NOTES
On peut voir les choses comme ca, en tout c'est comme ca que mon travaille peut
se résumer. Et en faite on les trois chose importante et qui faut apprendre a
gérer, les données, le code et le modèle.

On va voir comment gérer la complexité qui peut venir de chacun de ses axes.
#+END_NOTES

** Méthode de développement d'un modèle de ml
#+ATTR_HTML: :width 50%
[[./figures/800px-CRISP-DM_Process_Diagram.png]]
** Exploration des données et compréhension du problème client
#+ATTR_HTML: :width 50%
[[./figures/800px-CRISP-DM_Process_Diagram_0.png]]
** Exploration des données et compréhension du problème client
*Objectif*
- Verifier l'adéquation entre les données et le problème client
- Comprendre les données pour en extraire les variables les plus importantes
- Tester la qualité des données et dectecter des anomalies
- Commencer à refléchire au possbilité pour les modèles
#+BEGIN_NOTES
Pendant cette étape on trace des graphiques. C'est locasion de montrer des
graphique resumant les données au client afin de tester notre comprehenssion des
données.
#+END_NOTES
** Preparation des données et modélisation
#+ATTR_HTML: :width 50%
[[./figures/800px-CRISP-DM_Process_Diagram_1.png]]

** Preparation des données et modélisation
*Exemple : classification mail indésirable*
- Préparation des données : on compte les mots grossiers.
- Modèles : Support Vector Machine

*Exemple : système de recommandation*
- Préparation des donées : Age, sex, temps passer sur les vidéos
- Modèle : Factorisation de matrice + Knn

#+BEGIN_NOTES
- C'est la partie interessante d'un point vu vraiment machine learning
- Ou on va tester plusieurs modèles, plusieurs extraction
#+END_NOTES
** Évaluation
#+ATTR_HTML: :width 50%
[[./figures/800px-CRISP-DM_Process_Diagram_2.png]]
** Évaluation : Découpage des données
:LOGBOOK:
- Note taken on [2021-01-25 lun. 13:34] \\
  - metrique d'evaluation
  - découpage du jeux de données
  - et on bouble pour s'aligner sur les attentes du client
:END:
*Train, val, test*
- jeu d'entrainement : utiliser pour entrainer les paramêtre du modèle
- jeu de validation : utiliser pour tester les performance du modèle pendant la
  phase d'entrainement. Permet d'éviter le sur apprentissage.
- jeu de test : jamais vu pendant l'entrainement,

*Comment découper les données*
- au hasard
- en suivant une variable : l'années, la chaine de production etc

#+BEGIN_NOTES
- sur apprentissage: on apprent par coeur les données d'entrainement mais peut
  pas généraliser a nouvelles données.
#+END_NOTES
** Évaluation : métriques
*Métrique de performance* : mesure la performance du modèle sur les données de
  validation et de test.

  *Exemples* :
  - le taux de faux positif du système de dectection de fraud bancaire
  - l'erreur moyenne d'un système de prediction de la consomation energetique
    d'un batiment
** Évaluation : métriques
*Métriques metiers* : mesure l'intérêt du modèle d'un point de vu metier,
  souvant en argent.

  *Exemples* :
  - L'argent économisé en évitant les fraudes.
  - L'argent économisé en adaptant l'abonnement chez le fournisseur d'energie.

** Quelques (bonnes) pratiques : organisation des projets

#+BEGIN_EXAMPLE
├── Makefile           <- avec des commandes comme make data ou make train
├── README.md          <- Point de départ
├── data
│   ├── external       <- Données venant d'un tierce
│   ├── interim        <- Données transformées intermédiaires
│   ├── processed      <- Données finales, prètes pour les algos
│   └── raw            <- Les données d'origine, immuables !
│
├── docs               <- La documentation du projet (exemple: Sphinx ou MkDocs)
│
├── models             <- Modèles entrainés
│
├── notebooks          <- Les notebooks (exemple: Jupyter, Rmarkdown)
│
├── references         <- Manuel, présentation, doc etc.
│
├── reports            <- Rapports
│   └── figures        <- figures des rapports
│
├── requirements.txt   <- Pour reproduire l'environnement de l'analyse, exemple
│                         généré avec `pip freeze > requirements.txt`
│
├── src                <- Code source du projet (package python/R)
#+END_EXAMPLE

#+BEGIN_NOTES
- Pour etre plus pratique...
#+END_NOTES
** Quelques (bonnes) pratiques : le versionning
*Du code*
- @@html:<img src="./figures/logo_git.png" width="110" height="46" alt="Git" style="border: 0;" />@@

*Des données et des modèles*
- git annex
- git lfs
- Data Version Control (dvc)
** Quelques (bonnes) pratiques : les notebooks
#+REVEAL_HTML: <div class="column" style="float:left; width: 30%">
*Exemples d'outil*
- Jupyter
- Rmarkdown
- Zeppelin

#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class="column" style="float:right; width: 70%">

#+ATTR_HTML: :width 80%
[[./figures/example-notebook.png]]
#+REVEAL_HTML: </div>

#+BEGIN_NOTES
- un notebooks un environnement de dévellopement ou on peut coder et decrire ce
  que l'on code (litterate programming)
- les sorties du code sont capturé et peuvent être reprise plus tard
- Très pratique quand on fait des exploration et pour discuter/présenter autour
  des résultats
#+END_NOTES
** Quelques (bonnes) pratiques : test driven development
- On écrit d'abord le test puis le code qui correspond
- Permet par exemple de tester une /pipeline/ d'apprentissage

#+BEGIN_NOTES
- C'est une bonne pratique de dev en général
#+END_NOTES

** Déploiement ?

#+ATTR_HTML: :align middle
[[./figures/mem_prod.png]]

#+BEGIN_NOTES
On a un modèle aligné avec les attentes du client mais comment on peut le
transformer en quelque chose d'utile pour le client ? Comment on l'integre dans
le système du client ? C'est la que ca devient compliqué en faite.
#+END_NOTES

* Déploiment d'un modèle d'apprentissage automatique
** Qu'est-ce que la production ?
:PROPERTIES:
:ID:       fd30cba5-326c-4386-918f-210d26ed789d
:END:

[[attachment:_20210126_101042screenshot.png]]

- dev : choix des /features/ et du modèle
- build : entrainement du modèle sur le jeu d'entraînement
- test  : test du modèle sur le jeu de test
- deploy : packaging du modèle et du code d'inference du modèle
- provision : allocation des ressource faire tourner le modèle
- monitor : surveillance des performance du modèle
- operate : gestion du système en marche

#+BEGIN_NOTES
- Nous on a vu la partie dev mais la partie prod parait très éloigné
- Comment notre modèle va s'integrer dans ca ?
#+END_NOTES
** Quelques exemples de catastrophe : boite noire
Un modèle est composé de plein de paramètres appris sur des données, il est
impossible de d'anticiper tout les comportements possible sur des nouvelles
données.

*Comment le modèle réagit à des données un peu différente ?*

*Exemple*
- Comment un modèle de reconnaissance facial n'aurait vu que des indidus
  européen réagirait avec des individus asiatique ?

#+BEGIN_NOTES
- Contrairement à un algo qu'on aurait codé ..
- En production il faut s'attendre à avoir tout type de données et les résultats
  sur des nouvelles données peuvent conduire à des comportement très inatedu et
  embetant
#+END_NOTES
*** refs
[[pdf:~/Private/bibliotheque/science/datascience/fastai/howard2020deep.pdf::110++0.00;;annot-110-0][howard2020deep.pdf: Page 110; Quoting: How to Avoid Disaster]]
** Quelques exemples de catastrophe : boucle de rétroaction
:PROPERTIES:
:ID:       e5ba9faf-eebc-4a9d-b360-eab454e0752e
:END:

#+REVEAL_HTML: <div class="column" style="float:left; width: 30%">
[[attachment:_20210126_095540screenshot.png]]
#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class="column" style="float:right; width: 70%">
*Exemple*
- Les modèle de recomendation de youtube propose du contenue pour optimiser le
  temps de visionnage a partir des préference des utilisateurs
- 70 % du contenu visionné sur youtube est issu de l'algorithme de recomentation
- Donc l'algorithme de youtube à une influence sur les préférences des utilisateurs
#+REVEAL_HTML: </div>

#+BEGIN_NOTES
-  Cela arrive quand la sortie un modèle à une influence sur les données
  utilisée pour construire le modèle.
...
- Comme l'etre humain a tendance a être attiré par le contenue controversé et
  putaclick, des vidéo conspirationniste peuvent être de plus en plus recommandé.
#+END_NOTES
*** References :noexport:
[[pdf:~/Private/bibliotheque/science/datascience/fastai/howard2020deep.pdf::119++0.00;;annot-119-6][howard2020deep.pdf: Page 119; Quoting: Feedback Loops: YouTube’s Recommendation System]]
** Comment éviter la catastrophe ?
:PROPERTIES:
:ID:       64407a0d-07be-443a-84f9-ecd309a18a0b
:END:

Une strategie : le déploiment progressif du modèle

[[attachment:_20210126_100229screenshot.png]]


#+BEGIN_NOTES
- Quand c'est possible on garde le partie manuel du processus et on lance le
  modèle en paralelle (dans l'industrie ca ce fait beaucoup quand on veux
  remplacer une tache effectué par un opérateur par un algorithme de machine
  learning).
- On lance le modèle pour une partie des utilisateur seulement (en industrie on utilise le modèle sur une chaine de production seulement).
- Et on étant le déploiment du modèle à l'ensemble des utilisateur. En prenant
  soin d'itentifier ce qui ne pas fonctionner et faire remonter les log et visualisation pour debuguer le système.
#+END_NOTES
*** refs
- [[pdf:~/Private/bibliotheque/science/datascience/fastai/howard2020deep.pdf::112++3.62;;annot-112-1][howard2020deep.pdf: Page 112; Quoting: Figure 2-5. Deployment process]]

** Le DevOps
[[./figures/dev_ops.png]]
#+BEGIN_NOTES
- On a un processus de deploiement progressif du modèle mais on ne sais toujours
  pas comment deployer effectivement notre model
- Le processus de devellopement en machine learning qu'on vient de voir favorise
  un fonctionnement en silo. Entre une équipe de data scientiste qui developpe
  des modeles et une équipe qui s'occupe des les integrer au produit final
- Ce mode de fonctionnement peut fonctionner pour la mise en production d'un
  premier modèle
- Mais sur le long terme ca peut grandement ralentire la mise en production et
  les devellopement future du modèles.
#+END_NOTES
** Le DevOps
[[./figures/devops.png]]
#+BEGIN_NOTES
- C'est pour cette raison que les équipes on maintenant tendance a s'organiser en une seul équipe centré sur un objectif, qui mettre en production le modèle.
- C'est la qu'on parle de DevOps. C'est cette facon de s'organiser
#+END_NOTES
*** refs :noexport:
- https://azure.microsoft.com/fr-fr/blog/getting-ai-ml-and-devops-working-better-together/
** Les grands principes du DevOps

#+REVEAL_HTML: <div class="column" style="float:left; width: 50%">
#+ATTR_HTML: :width 60%
[[./figures/devops_cycle.png]]
#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class="column" style="float:right; width: 50%">
- Gestion du code sources : git
- Gestion des builds : entrainement et versionnage des modèles
- Automatisation des test : test du modèle sur les jeux de test
- /Infrastructure as code/ : Docker
- Deploiement continue
- /Monitoring/ des performances du modèles en production

#+REVEAL_HTML: </div>


*** refs
- [[pdf:~/Private/mobile/ddl/Hands-on DevOps_ Explore the concept of continuous delivery and integrate it with data science concepts.pdf::55++0.00;;annot-55-0][Hands-on DevOps_ Explore the concept of continuous delivery and integrate it with data science concepts.pdf: Page 55; Quoting: DevOps process]]
** Les architectures monolique
:PROPERTIES:
:ID:       65d23663-050b-4b98-9556-2e33d1710eca
:END:

[[attachment:_20210127_092932screenshot.png]]
*** refs :noexport:
- [[pdf:~/Private/mobile/ddl/Hands-on DevOps_ Explore the concept of continuous delivery and integrate it with data science concepts.pdf::340++0.00;;annot-340-0][Hands-on DevOps_ Explore the concept of continuous delivery and integrate it with data science concepts.pdf: Page 340; Quoting: Microservices core patterns]]
** Les architectures monolique
*Désavantages*
- Grosse application difficile a maintenir
- Ne favorise pas la modularité
- Le passage a l'echelle est compliqué
- Toute l'application s'engage à utilisé une /stack/ techno

#+BEGIN_NOTES
-
- Qui favorise le deploiement, devellopement et les test
- Par exemple : car on doit faire passer toute lapplication à l'echelle alors
  que seulement un sous système peut avoir besoin de plus de puissance
  calculatoire
- C'est peut être le plus gros problème en ML car c'est un domaine qui va très
  vite. On aimerai bien pouvoir faire évoluer la brick du sous système de la
  partie ML sans faire evoluer le reste.
#+END_NOTES

** Les architectures en microservices
:PROPERTIES:
:ID:       ec226db8-20e4-4219-a163-3da0151164ad
:END:

[[attachment:_20210127_101100screenshot.png]]
#+BEGIN_NOTES
- Pour éviter les defauts on prefere decouper l'application en sous système qu'on implémente sous forme de microservice
- chaque microservice definie une interface, c'est le contrat du service rendu.
- chaque micro service est libre de ce qu'il se passe à l'interieur.
#+END_NOTES
*** refs :noexport:
- [[pdf:~/Private/mobile/ddl/Hands-on DevOps_ Explore the concept of continuous delivery and integrate it with data science concepts.pdf::342++0.00;;annot-342-0][Hands-on DevOps_ Explore the concept of continuous delivery and integrate it with data science concepts.pdf: Page 342; Quoting: Microservices architecture]]

** Le déploiment continues avec de l'apprentissage automomatique :ATTACH:
:PROPERTIES:
:ID:       c9f6ceb1-9e84-4bc0-a89e-d9538c1a73ef
:END:
:LOGBOOK:
- Note taken on [2021-01-27 mer. 10:17] \\
  refs: [[https://martinfowler.com/articles/cd4ml.html?utm_campaign=Data_Elixir&utm_medium=email&utm_source=Data_Elixir_250#TheEnd-to-endCd4mlProcess][The End-to-End CD4ML Process]]
:END:

[[attachment:_20210127_102503screenshot.png]]


#+BEGIN_NOTES
Si on résume ce qui à été dit on peut voir le déploiement d'une solution reposant
sur le /machine learning/ comme la succession de ces étapes.

On voit ici les différentes étapes du processus de déploiement ainsi que les
artefact qui correspondent à chaque étape.

1. on entrain des modèle sur des données static (train

2. on a des modèle candidat qu'on peut comparé sur des donénes de test (jamais vu pendant l'entrainement

3. un modèle est choisie et on peut le testé en tant que modèle en production
   c'est dans sont enviromment de prod fournissant des prédiction à travers une api
4. puis on déploie et on monitor le comportement du modèle en production. Ces
   bug, si c'est de la prédiction on voir si il a juste ou pas ?
5. et On recommence
#+END_NOTES

* Ce qu'il faut retenir
- Il faut s'avoir gérer du code, des données et des modèles.
- La mise en production d'un modèle peut conduire a des catastrophes. Il faut
  les anticiper et faire remonter les bon indicateurs pour résoudre les
  problèmes.
- Une organisation centré sur le problème client et la conception du modèle est
  bien pour un prototype
- Pour des systèmes intégrant un modèle, le DevOps à fait ses preuves.
* References
*Livres*
- [[https://www.oreilly.com/library/view/deep-learning-for/9781492045519/][Deep Learning for Coders with fastai and PyTorch]] (chapitre 2. From Model to
  Production et chapitre 3. Data Ethics)
- [[https://www.oreilly.com/library/view/hands-on-devops/9781788471183/][Hands-on DevOps]]

*Articles*
- [[https://martinfowler.com/articles/cd4ml.html?utm_campaign=Data_Elixir&utm_medium=email&utm_source=Data_Elixir_250][Continuous Delivery for Machine Learning]] (mise en place d'un pipe CD avec DVC)
- [[https://azure.microsoft.com/fr-fr/blog/getting-ai-ml-and-devops-working-better-together/][Getting AI/ML and DevOps working better together]]
